{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from pickle import load\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ALC_processing import * #imports all functions from chatbot.py\n",
    "\n",
    "# The lines below auto-reload the code you write in chatbot.py \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe Gigaword 100 dimensions\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixfile = \"6B.100d.bin\"\n",
    "A = np.fromfile(matrixfile, dtype=np.float32)\n",
    "d = int(np.sqrt(A.shape[0]))\n",
    "assert (\n",
    "    d == next(iter(word_vectors)).shape[0]\n",
    "), \"induction matrix dimension and word embedding dimension must be the same\"\n",
    "A = A.reshape(d, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../processed_corpus_list.pickle\", \"rb\") as handle:\n",
    "    corpus = np.array(load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../tokens-exploratory/exploratory_table.pickle\", \"rb\") as handle:\n",
    "    table = load(handle)\n",
    "\n",
    "tokens = table.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=6)]: Done   2 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=6)]: Done   3 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=6)]: Done   4 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=6)]: Done   5 tasks      | elapsed:   14.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[39mreturn\u001b[39;00m alc\u001b[39m.\u001b[39mprocess(word)\n\u001b[1;32m      4\u001b[0m alc \u001b[39m=\u001b[39m ALCProcessor(corpus, word_vectors, A)\n\u001b[0;32m----> 6\u001b[0m output \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m)(delayed(process_wrapper)(alc, token) \u001b[39mfor\u001b[39;49;00m token \u001b[39min\u001b[39;49;00m tokens)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp-research/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp-research/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp-research/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp-research/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp-research/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp-research/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_wrapper(alc, word: str):\n",
    "    return alc.process(word)\n",
    "\n",
    "alc = ALCProcessor(corpus, word_vectors, A)\n",
    "\n",
    "output = Parallel(n_jobs=6, verbose=100, prefer=\"threads\")(delayed(process_wrapper)(alc, token) for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alc_stepone.pickle\", \"rb\") as handle:\n",
    "    alc_stepone = load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), 'Y': array([[ 0.06257202, -0.18774825,  0.08009695, ..., -0.07900907,\n",
      "        -0.21536636,  0.10740004],\n",
      "       [ 0.03308833, -0.06322007,  0.0676566 , ..., -0.03252716,\n",
      "        -0.08372094,  0.07895882],\n",
      "       [-0.01809815, -0.00797987,  0.07186805, ..., -0.0360515 ,\n",
      "        -0.1691525 ,  0.10561158],\n",
      "       ...,\n",
      "       [ 0.06257202, -0.18774825,  0.08009695, ..., -0.07900907,\n",
      "        -0.21536636,  0.10740004],\n",
      "       [-0.00826409, -0.01695172,  0.1128075 , ..., -0.0820265 ,\n",
      "        -0.12314195,  0.09000929],\n",
      "       [-0.02440384,  0.0057713 ,  0.01242905, ...,  0.11304753,\n",
      "        -0.08281481,  0.09820908]])}\n"
     ]
    }
   ],
   "source": [
    "print(alc_stepone[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'tokens': ['i', 'think', 'so', ',', 'justice', 'alito', '.', 'i', 'think', ',', 'first', 'of', 'all', ',', 'a', 'to', 'this', 'serious', 'constitutional', 'problem', ',', 'you', 'have', 'federal', 'property', 'right', 'that', 'are', '--', 'have', 'been', 'granted', 'and', 'that', 'are', 'private', 'property', 'right', ',', 'and', 'state', 'are', 'infringing', 'without', 'paying', 'for', 'them', '.', 'that', 'is', 'a', 'fundamental', 'intrusion', '.', 'that', 'is', 'a', 'fundamental', 'constitutional', 'problem', '.', 'and', 'i', 'think', 'congress', ',', 'if', 'it', 'ha', 'a', 'remedy', 'that', 'is', 'conscientiously', 'tailored', 'around', 'that', ',', 'should', 'have', ',', 'a', 'the', 'court', 'put', 'it', 'in', 'city', 'of', 'boerne', '--'], 'gender': 'M'}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[24:25]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
